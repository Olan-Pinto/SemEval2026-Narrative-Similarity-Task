{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e58cf1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Package Conflicts\n",
    "\n",
    "# !pip uninstall -y transformers huggingface_hub\n",
    "# !pip cache purge\n",
    "# !pip install \"transformers==4.56.1\" \"huggingface_hub==0.35.0\"\n",
    "# !pip install -U sentence-transformers==5.1.0\n",
    "\n",
    "# !pip show torch\n",
    "\n",
    "# !pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "\n",
    "# !pip install hf_xet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10cd26ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ec3a24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _encode_longformer(texts):\n",
    "    \"\"\"Encode using Longformer with mean pooling\"\"\"\n",
    "    embeddings = []\n",
    "    \n",
    "    for text in texts:\n",
    "        # Tokenize\n",
    "        inputs = tokenizer(text, return_tensors='pt', \n",
    "                                truncation=True, max_length=4096, \n",
    "                                padding=True).to(device)\n",
    "    \n",
    "        # Get embeddings\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            # Mean pooling over tokens\n",
    "            embedding = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "            embeddings.append(embedding[0])\n",
    "    \n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b845104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(texts):\n",
    "    \"\"\"Encode texts into embeddings\"\"\"\n",
    "    if model_type == 'sbert':\n",
    "        return model.encode(texts, show_progress_bar=False, convert_to_numpy=True)\n",
    "    elif model_type == 'longformer':\n",
    "        return _encode_longformer(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09a32c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_triple(anchor, text_a, text_b):\n",
    "    \"\"\"\n",
    "    Predict which text is more similar to anchor\n",
    "    \n",
    "    Returns:\n",
    "        True if text_a is closer, False if text_b is closer\n",
    "    \"\"\"\n",
    "    # Encode all three texts\n",
    "    embeddings = encode([anchor, text_a, text_b])\n",
    "    \n",
    "    # Calculate cosine similarities\n",
    "    sim_a = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]\n",
    "    sim_b = cosine_similarity([embeddings[0]], [embeddings[2]])[0][0]\n",
    "    \n",
    "    return sim_a > sim_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7436ec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(df):\n",
    "    \"\"\"\n",
    "    Evaluate on dataset\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with columns ['anchor_text', 'text_a', 'text_b', 'text_a_is_closer']\n",
    "    \n",
    "    Returns:\n",
    "        accuracy, predictions, similarities\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    similarities_a = []\n",
    "    similarities_b = []\n",
    "    \n",
    "    print(f\"Evaluating {len(df)} samples...\")\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        # Encode\n",
    "        embeddings = encode([row['anchor_text'], row['text_a'], row['text_b']])\n",
    "        \n",
    "        # Calculate similarities\n",
    "        sim_a = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]\n",
    "        sim_b = cosine_similarity([embeddings[0]], [embeddings[2]])[0][0]\n",
    "        \n",
    "        # Predict\n",
    "        pred = sim_a > sim_b\n",
    "        predictions.append(pred)\n",
    "        similarities_a.append(sim_a)\n",
    "        similarities_b.append(sim_b)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    df['prediction'] = predictions\n",
    "    df['sim_a'] = similarities_a\n",
    "    df['sim_b'] = similarities_b\n",
    "    accuracy = (df['prediction'] == df['text_a_is_closer']).mean()\n",
    "    \n",
    "    return accuracy, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a201dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anchor_text</th>\n",
       "      <th>text_a</th>\n",
       "      <th>text_b</th>\n",
       "      <th>text_a_is_closer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The film takes place in Burma and India during...</td>\n",
       "      <td>During the Irish War of Independence in 1921, ...</td>\n",
       "      <td>1914, German advance through Belgium: the youn...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The foursome (Gérard Rinaldi, Jean Sarrus, Gér...</td>\n",
       "      <td>The old grandmother Tina arrives in town to at...</td>\n",
       "      <td>Brendan Byers III is a rich playboy who enlist...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anna (Gry Bay) is a single woman who seeks to ...</td>\n",
       "      <td>A psychological portrait of relationships and ...</td>\n",
       "      <td>The story of this film starts with the difficu...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A stevedore in Thessaloniki, Greece, Salamo Ar...</td>\n",
       "      <td>The story takes place in Berlin in 1940, where...</td>\n",
       "      <td>During the World War II, in the 1930s to 1940s...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A teenage girl accuses her primary schoolteach...</td>\n",
       "      <td>Art Brooks and Kelly Moore are a couple who ge...</td>\n",
       "      <td>Tonino is a high school student, in love with ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         anchor_text  \\\n",
       "0  The film takes place in Burma and India during...   \n",
       "1  The foursome (Gérard Rinaldi, Jean Sarrus, Gér...   \n",
       "2  Anna (Gry Bay) is a single woman who seeks to ...   \n",
       "3  A stevedore in Thessaloniki, Greece, Salamo Ar...   \n",
       "4  A teenage girl accuses her primary schoolteach...   \n",
       "\n",
       "                                              text_a  \\\n",
       "0  During the Irish War of Independence in 1921, ...   \n",
       "1  The old grandmother Tina arrives in town to at...   \n",
       "2  A psychological portrait of relationships and ...   \n",
       "3  The story takes place in Berlin in 1940, where...   \n",
       "4  Art Brooks and Kelly Moore are a couple who ge...   \n",
       "\n",
       "                                              text_b  text_a_is_closer  \n",
       "0  1914, German advance through Belgium: the youn...             False  \n",
       "1  Brendan Byers III is a rich playboy who enlist...              True  \n",
       "2  The story of this film starts with the difficu...              True  \n",
       "3  During the World War II, in the 1930s to 1940s...              True  \n",
       "4  Tonino is a high school student, in love with ...             False  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('./Data/SemEval2026-Task_4-sample-v1/sample_track_a.jsonl', lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b28971f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 39 samples\n",
      "Columns: ['anchor_text', 'text_a', 'text_b', 'text_a_is_closer']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loaded {len(df)} samples\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d332ceb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sentence-transformers/all-MiniLM-L6-v2 on cpu...\n",
      "Evaluating 39 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:02<00:00, 14.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.5897 (58.97%)\n",
      "  Correct: 23/39\n",
      "  Error cases: 16\n",
      "Loading sentence-transformers/all-mpnet-base-v2 on cpu...\n",
      "Evaluating 39 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:17<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.6410 (64.10%)\n",
      "  Correct: 25/39\n",
      "  Error cases: 14\n",
      "Loading allenai/longformer-base-4096 on cpu...\n",
      "Evaluating 39 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [01:29<00:00,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.5897 (58.97%)\n",
      "  Correct: 23/39\n",
      "  Error cases: 16\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "                                  Model       Type Accuracy Percentage\n",
      " sentence-transformers/all-MiniLM-L6-v2      sbert   0.5897     58.97%\n",
      "sentence-transformers/all-mpnet-base-v2      sbert   0.6410     64.10%\n",
      "           allenai/longformer-base-4096 longformer   0.5897     58.97%\n",
      "\n",
      " Best Model: sentence-transformers/all-mpnet-base-v2\n",
      "   Accuracy: 0.6410 (64.10%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models_to_test = [\n",
    "    ('sentence-transformers/all-MiniLM-L6-v2', 'sbert'),\n",
    "    ('sentence-transformers/all-mpnet-base-v2', 'sbert'),\n",
    "    ('allenai/longformer-base-4096', 'longformer'),\n",
    "]\n",
    "results =[]\n",
    "for mn,mt in models_to_test:\n",
    "    model_name=mn\n",
    "    model_type=mt\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Loading {model_name} on {device}...\")\n",
    "\n",
    "    if model_type == 'sbert':\n",
    "        model = SentenceTransformer(model_name, device=device)\n",
    "    elif model_type == 'longformer':\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "    accuracy, predictions_df = evaluate(df.copy())\n",
    "\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        'model': model_name,\n",
    "        'type': model_type,\n",
    "        'accuracy': accuracy,\n",
    "        'predictions_df': predictions_df\n",
    "    })\n",
    "\n",
    "    print(f\"\\nAccuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "    # Show some statistics\n",
    "    correct = (predictions_df['prediction'] == predictions_df['text_a_is_closer']).sum()\n",
    "    total = len(predictions_df)\n",
    "    print(f\"  Correct: {correct}/{total}\")\n",
    "\n",
    "    # Analyze errors\n",
    "    errors = predictions_df[predictions_df['prediction'] != predictions_df['text_a_is_closer']]\n",
    "    if len(errors) > 0:\n",
    "        avg_sim_diff = (errors['sim_a'] - errors['sim_b']).abs().mean()\n",
    "        print(f\"  Error cases: {len(errors)}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "summary_df = pd.DataFrame([\n",
    "    {\n",
    "        'Model': r['model'],\n",
    "        'Type': r['type'],\n",
    "        'Accuracy': f\"{r['accuracy']:.4f}\" if 'accuracy' in r else 'ERROR',\n",
    "        'Percentage': f\"{r['accuracy']*100:.2f}%\" if 'accuracy' in r else 'ERROR'\n",
    "    }\n",
    "    for r in results\n",
    "])\n",
    "\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Find best model\n",
    "valid_results = [r for r in results if 'accuracy' in r and r['accuracy'] > 0]\n",
    "if valid_results:\n",
    "    best = max(valid_results, key=lambda x: x['accuracy'])\n",
    "    print(f\"\\n Best Model: {best['model']}\")\n",
    "    print(f\"   Accuracy: {best['accuracy']:.4f} ({best['accuracy']*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48480d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def run_baseline_comparison(data_path, models_config):\n",
    "    \"\"\"\n",
    "    Run comparison of multiple baseline models\n",
    "    \n",
    "    Args:\n",
    "        data_path: Path to CSV/JSON with data\n",
    "        models_config: List of (model_name, model_type) tuples\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    print(f\"Loading data from {data_path}...\")\n",
    "    if data_path.endswith('.csv'):\n",
    "        df = pd.read_csv(data_path)\n",
    "    elif data_path.endswith('.json'):\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Data must be CSV or JSON\")\n",
    "    \n",
    "    print(f\"Loaded {len(df)} samples\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Verify required columns\n",
    "    required = ['anchor', 'text_a', 'text_b', 'text_a_is_closer']\n",
    "    missing = set(required) - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "    \n",
    "    # Results storage\n",
    "    results = []\n",
    "    \n",
    "    # Test each model\n",
    "    for model_name, model_type in models_config:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Testing: {model_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            # Initialize model\n",
    "            baseline = NarrativeSimilarityBaseline(model_name, model_type)\n",
    "            \n",
    "            # Evaluate\n",
    "            accuracy, predictions_df = baseline.evaluate(df.copy())\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'model': model_name,\n",
    "                'type': model_type,\n",
    "                'accuracy': accuracy,\n",
    "                'predictions_df': predictions_df\n",
    "            })\n",
    "            \n",
    "            print(f\"\\n✓ Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "            \n",
    "            # Show some statistics\n",
    "            correct = (predictions_df['prediction'] == predictions_df['text_a_is_closer']).sum()\n",
    "            total = len(predictions_df)\n",
    "            print(f\"  Correct: {correct}/{total}\")\n",
    "            \n",
    "            # Analyze errors\n",
    "            errors = predictions_df[predictions_df['prediction'] != predictions_df['text_a_is_closer']]\n",
    "            if len(errors) > 0:\n",
    "                avg_sim_diff = (errors['sim_a'] - errors['sim_b']).abs().mean()\n",
    "                print(f\"  Error cases: {len(errors)}\")\n",
    "                print(f\"  Avg similarity difference in errors: {avg_sim_diff:.4f}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error with {model_name}: {str(e)}\")\n",
    "            results.append({\n",
    "                'model': model_name,\n",
    "                'type': model_type,\n",
    "                'accuracy': 0.0,\n",
    "                'error': str(e)\n",
    "            })\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    summary_df = pd.DataFrame([\n",
    "        {\n",
    "            'Model': r['model'],\n",
    "            'Type': r['type'],\n",
    "            'Accuracy': f\"{r['accuracy']:.4f}\" if 'accuracy' in r else 'ERROR',\n",
    "            'Percentage': f\"{r['accuracy']*100:.2f}%\" if 'accuracy' in r else 'ERROR'\n",
    "        }\n",
    "        for r in results\n",
    "    ])\n",
    "    \n",
    "    print(summary_df.to_string(index=False))\n",
    "    \n",
    "    # Find best model\n",
    "    valid_results = [r for r in results if 'accuracy' in r and r['accuracy'] > 0]\n",
    "    if valid_results:\n",
    "        best = max(valid_results, key=lambda x: x['accuracy'])\n",
    "        print(f\"\\n🏆 Best Model: {best['model']}\")\n",
    "        print(f\"   Accuracy: {best['accuracy']:.4f} ({best['accuracy']*100:.2f}%)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define models to compare\n",
    "\n",
    "    \n",
    "    # Run comparison\n",
    "    # Replace 'your_data.csv' with your actual file path\n",
    "    results = run_baseline_comparison(\n",
    "        data_path='your_data.csv',  # UPDATE THIS\n",
    "        models_config=models_to_test\n",
    "    )\n",
    "    \n",
    "    # Optional: Save detailed results\n",
    "    for result in results:\n",
    "        if 'predictions_df' in result:\n",
    "            model_safe_name = result['model'].replace('/', '_')\n",
    "            result['predictions_df'].to_csv(\n",
    "                f\"predictions_{model_safe_name}.csv\", \n",
    "                index=False\n",
    "            )\n",
    "            print(f\"Saved predictions to: predictions_{model_safe_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e3292c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "model = AutoModel.from_pretrained(\"allenai/longformer-base-4096\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28e083a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
